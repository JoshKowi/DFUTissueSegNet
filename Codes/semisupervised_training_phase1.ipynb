{"cells":[{"cell_type":"markdown","metadata":{"id":"8XKGaVdvIuwq"},"source":["**Semi-supervised training: Phase 1**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25911,"status":"ok","timestamp":1700803422608,"user":{"displayName":"mrinal kanti Dhar","userId":"05916082757615620540"},"user_tz":360},"id":"NtZrR6Lpamzt","outputId":"9a958d66-1380-4782-dffb-7670f4833bf6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wKYTa1YNahpR"},"outputs":[],"source":["import sys\n","\n","sys.path.append('/content/drive/MyDrive/Wound_tissue_segmentation')\n","sys.path.append('/content/drive/MyDrive/Wound_tissue_segmentation/utils')\n","sys.path.append('/content/drive/MyDrive/Wound_tissue_segmentation/wound_lib')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wWvUuJ7xZ17E"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset as BaseDataset\n","import albumentations as albu\n","import cv2\n","import numpy as np\n","import segmentation_models_pytorch as smp\n","from segmentation_models_pytorch.utils import metrics, losses, base\n","import random\n","import matplotlib.pyplot as plt\n","import os\n","from copy import deepcopy\n","from datetime import datetime\n","import torch.nn.functional as F\n","import time\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"u1TTozpn-D8o"},"source":["## Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nx_iN5gGarSj"},"outputs":[],"source":["class Dataset(BaseDataset):\n","    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n","\n","    Args:\n","        images_dir (str): path to images folder\n","        masks_dir (str): path to segmentation masks folder\n","        augmentation (albumentations.Compose): data transfromation pipeline\n","            (e.g. flip, scale, etc.)\n","        preprocessing (albumentations.Compose): data preprocessing\n","            (e.g. noralization, shape manipulation, etc.)\n","\n","    \"\"\"\n","\n","    def __init__(\n","            self,\n","            list_IDs,\n","            images_dir,\n","            masks_dir,\n","            augmentation=None,\n","            preprocessing=None,\n","            to_categorical:bool=False,\n","            resize=(False, (256, 256)), # To resize, the first value has to be True\n","            n_classes:int=6,\n","    ):\n","        self.ids = list_IDs\n","        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n","        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n","\n","        self.augmentation = augmentation\n","        self.preprocessing = preprocessing\n","        self.to_categorical = to_categorical\n","        self.resize = resize\n","        self.n_classes = n_classes\n","\n","    def __getitem__(self, i):\n","\n","        # read data\n","        image = cv2.imread(self.images_fps[i])\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        mask = cv2.imread(self.masks_fps[i], 0)     # ----------------- pay attention ------------------ #\n","\n","        if self.resize[0]:\n","            image = cv2.resize(image, self.resize[1], interpolation=cv2.INTER_NEAREST)\n","            mask = cv2.resize(mask, self.resize[1], interpolation=cv2.INTER_NEAREST)\n","\n","        # mask = mask/255.0   # converting mask to (0 and 1) # ----------------- pay attention ------------------ #\n","        mask = np.expand_dims(mask, axis=-1)  # adding channel axis # ----------------- pay attention ------------------ #\n","\n","        # apply augmentations\n","        if self.augmentation:\n","            sample = self.augmentation(image=image, mask=mask)\n","            image, mask = sample['image'], sample['mask']\n","\n","        # apply preprocessing\n","        if self.preprocessing:\n","            sample = self.preprocessing(image=image, mask=mask)\n","            image, mask = sample['image'], sample['mask']\n","\n","        if self.to_categorical:\n","            mask = torch.from_numpy(mask)\n","            mask = F.one_hot(mask.long(), num_classes=self.n_classes)\n","            mask = mask.type(torch.float32)\n","            mask = mask.numpy()\n","            mask = np.squeeze(mask)\n","\n","            mask = np.moveaxis(mask, -1, 0) # e.g. 6 x 512 x 512. Only for smp\n","\n","        # print('-----------------------------------------------')\n","        # print(image.dtype)\n","        # print(mask.shape)\n","\n","        return image, mask\n","\n","    def __len__(self):\n","        return len(self.ids)"]},{"cell_type":"markdown","metadata":{"id":"yB8RKETkALtF"},"source":["## Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T-ltFwaGAK3c"},"outputs":[],"source":["def get_training_augmentation():\n","    train_transform = [\n","\n","        albu.OneOf(\n","            [\n","                albu.HorizontalFlip(p=0.5),\n","                albu.VerticalFlip(p=0.5),\n","            ],\n","            p=0.8,\n","        ),\n","\n","        albu.OneOf(\n","            [\n","                albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0, p=0.1, border_mode=0), # scale only\n","                albu.ShiftScaleRotate(scale_limit=0, rotate_limit=30, shift_limit=0, p=0.1, border_mode=0), # rotate only\n","                albu.ShiftScaleRotate(scale_limit=0, rotate_limit=0, shift_limit=0.1, p=0.6, border_mode=0), # shift only\n","                albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=30, shift_limit=0.1, p=0.2, border_mode=0), # affine transform\n","            ],\n","            p=0.9,\n","        ),\n","\n","        albu.OneOf(\n","            [\n","                albu.Perspective(p=0.2),\n","                albu.GaussNoise(p=0.2),\n","                albu.Sharpen(p=0.2),\n","                albu.Blur(blur_limit=3, p=0.2),\n","                albu.MotionBlur(blur_limit=3, p=0.2),\n","            ],\n","            p=0.5,\n","        ),\n","\n","        albu.OneOf(\n","            [\n","                albu.CLAHE(p=0.25),\n","                albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.25),\n","                albu.RandomGamma(p=0.25),\n","                albu.HueSaturationValue(p=0.25),\n","            ],\n","            p=0.3,\n","        ),\n","\n","    ]\n","\n","    return albu.Compose(train_transform, p=0.9) # 90% augmentation probability\n","\n","\n","def get_validation_augmentation():\n","    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n","    test_transform = [\n","        # albu.PadIfNeeded(512, 512)\n","    ]\n","    return albu.Compose(test_transform)\n","\n","\n","def to_tensor(x, **kwargs):\n","    return x.transpose(2, 0, 1).astype('float32')\n","\n","\n","def get_preprocessing(preprocessing_fn):\n","    \"\"\"Construct preprocessing transform\n","\n","    Args:\n","        preprocessing_fn (callbale): data normalization function\n","            (can be specific for each pretrained neural network)\n","    Return:\n","        transform: albumentations.Compose\n","\n","    \"\"\"\n","\n","    _transform = [\n","        albu.Lambda(image=preprocessing_fn),\n","        albu.Lambda(image=to_tensor, mask=to_tensor),\n","    ]\n","    return albu.Compose(_transform)"]},{"cell_type":"markdown","metadata":{"id":"Z9xxDHfp_yFO"},"source":["## Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yq5o1vzBYxN0"},"outputs":[],"source":["# Parameters\n","BASE_MODEL = 'MiT+pscse'\n","ENCODER = 'mit_b3'\n","ENCODER_WEIGHTS = 'imagenet'\n","BATCH_SIZE = 16\n","n_classes = 4\n","ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","LR = 0.0001 # learning rate\n","EPOCHS = 500\n","WEIGHT_DECAY = 1e-5\n","SAVE_WEIGHTS_ONLY = True\n","RESIZE = (False, (256,256)) # if resize needed\n","TO_CATEGORICAL = True\n","SAVE_BEST_MODEL = True\n","SAVE_LAST_MODEL = False\n","\n","PERIOD = 10 # periodically save checkpoints\n","RAW_PREDICTION = False # if true, then stores raw predictions (i.e. before applying threshold)\n","RETRAIN = False\n","\n","# For early stopping\n","EARLY_STOP = True # True to activate early stopping\n","PATIENCE = 50 # for early stopping\n","\n","import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context"]},{"cell_type":"markdown","metadata":{"id":"aZUDgFCkKPlW"},"source":["## Helper function: save a model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"daug57SuKNIW"},"outputs":[],"source":["def save(model_path, epoch, model_state_dict, optimizer_state_dict):\n","\n","    state = {\n","        'epoch': epoch + 1,\n","        'state_dict': deepcopy(model_state_dict),\n","        'optimizer': deepcopy(optimizer_state_dict),\n","        }\n","\n","    torch.save(state, model_path)"]},{"cell_type":"markdown","metadata":{"id":"7qcadi38Ac5H"},"source":["## Loss, optimizer, metrics, and callbacks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"26g3jFOZyWmg"},"outputs":[],"source":["# Loss function\n","dice_loss = losses.DiceLoss()\n","focal_loss = losses.FocalLoss()\n","dce_loss = losses.DynamicCEAndSCELoss() # dynamic CE\n","\n","# Metrics\n","metrics = [\n","    metrics.IoU(threshold=0.5),\n","    metrics.Fscore(threshold=0.5),\n","]"]},{"cell_type":"markdown","metadata":{"id":"Mp9ohG-nyZzg"},"source":["\n","## Model Run"]},{"cell_type":"code","source":["# Create a function to read names from a text file, and add extensions\n","def read_names(txt_file, ext=\".png\"):\n","  with open(txt_file, \"r\") as f: names = f.readlines()\n","\n","  names = [name.strip(\"\\n\") for name in names] # remove newline\n","\n","  # Names are without extensions. So, add extensions\n","  names = [name + ext for name in names]\n","\n","  return names"],"metadata":{"id":"gZ9eWuHUFs75"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WwzQK4eOzwYz"},"outputs":[],"source":["dir_txt_save = '/content/drive/MyDrive/Wound_tissue_segmentation/texts/'\n","os.makedirs(dir_txt_save, exist_ok=True)\n","\n","# Read unsupervised names\n","dir_txt_load = '/content/drive/MyDrive/Wound_tissue_segmentation/Dataset/FUWound_mmseg_all_in_one_cropped_padded_selfSupervised'\n","unsup_names = read_names(os.path.join(dir_txt_load, 'Unsupervised_name.txt'), ext='.png')\n","\n","# Read supervised train, test, and val names\n","dir_txt = '/content/drive/MyDrive/Wound_tissue_segmentation/Dataset/dataset_MiT_v3+aug-added'\n","sup_IDs_train = read_names(os.path.join(dir_txt, 'labeled_train_names.txt'), ext='.png')\n","list_IDs_val = read_names(os.path.join(dir_txt, 'labeled_val_names.txt'), ext='.png')\n","list_IDs_test = read_names(os.path.join(dir_txt, 'test_names.txt'), ext='.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MwRA6u_4ZvyE"},"outputs":[],"source":["n_runs = 5 # No. of runs\n","\n","seeds = [random.randint(0, 5000) for _ in range(n_runs)] # generate 10 random seeds\n","\n","save_dir_pred_root = '/content/drive/MyDrive/Wound_tissue_segmentation/predictions'\n","os.makedirs(save_dir_pred_root, exist_ok = True)\n","\n","weight_factor = [1.0, 1.0, 1.0]\n","\n","for run, seed in enumerate(seeds):\n","\n","    print('===================================================================')\n","    print('===================================================================')\n","    print(f'=========================== run {run} ============================')\n","    print('===================================================================')\n","    print('===================================================================')\n","\n","    total_loss = base.HybridLoss(dice_loss, focal_loss, dce_loss, weight_factor)\n","\n","    start = time.time() # start of training\n","\n","    # Create a unique model name\n","    model_name = BASE_MODEL + '_padded_' + ENCODER + '_' + datetime.now().strftime('%Y-%m-%d_%H-%M-%S') + '_selfSupervised'\n","    print(model_name)\n","\n","    aux_params=dict(\n","        classes=n_classes,\n","        activation=ACTIVATION,\n","        dropout=0.1, # dropout ratio, default is None\n","    )\n","\n","    # create segmentation model with pretrained encoder\n","    model = smp.Unet(\n","        encoder_name=ENCODER,\n","        encoder_weights=ENCODER_WEIGHTS,\n","        # aux_params=aux_params,\n","        classes=n_classes,\n","        activation=ACTIVATION,\n","        decoder_attention_type='pscse',\n","    )\n","\n","    preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n","\n","    model.to(DEVICE)\n","\n","    # Optimizer\n","    optimizer = torch.optim.Adam([\n","        dict(params=model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY),\n","    ])\n","\n","    # Learning rate scheduler\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n","                                  factor=0.1,\n","                                  mode='min',\n","                                  patience=10,\n","                                  min_lr=0.00001,\n","                                  verbose=True,\n","                                  )\n","\n","    print(f'seed: {seed}')\n","\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","\n","    x_train_dir = x_valid_dir = x_test_dir = '/content/drive/MyDrive/Wound_tissue_segmentation/Dataset/FUWound_mmseg_all_in_one_cropped_padded_selfSupervised/images'\n","    y_train_dir = y_valid_dir = y_test_dir = '/content/drive/MyDrive/Wound_tissue_segmentation/Dataset/FUWound_mmseg_all_in_one_cropped_padded_selfSupervised/annotations'\n","\n","    random.seed(seed) # seed for random number generator\n","\n","    unsup_names_IDs = unsup_names.copy() # make a copy of unsupervised names\n","    random.shuffle(unsup_names_IDs) # shuffle unsupervised names\n","    unsup_names_IDs = unsup_names_IDs[:50] # take 50 unsupervised images\n","\n","    list_IDs_train = sup_IDs_train + unsup_names_IDs # supervised + unsupervised\n","\n","    print('No. of training images: ', len(list_IDs_train))\n","    print('No. of validation images: ', len(list_IDs_val))\n","    print('No. of test images: ', len(list_IDs_test))\n","\n","    # Save the randomly picked 50 unsupervised names in text files\n","    with open(os.path.join(dir_txt_save, model_name + '_unsup_train.txt'), \"w\") as f:\n","      for name in unsup_names_IDs: print(name, file=f)\n","\n","    # Checkpoint directory\n","    checkpoint_loc = '/content/drive/MyDrive/Wound_tissue_segmentation/checkpoints/' + model_name\n","\n","    # Create checkpoint directory if does not exist\n","    if not os.path.exists(checkpoint_loc): os.makedirs(checkpoint_loc)\n","\n","    # Dataloader ===================================================================\n","    train_dataset = Dataset(\n","        list_IDs_train,\n","        x_train_dir,\n","        y_train_dir,\n","        augmentation=get_training_augmentation(),\n","        preprocessing=get_preprocessing(preprocessing_fn),\n","        to_categorical=TO_CATEGORICAL,\n","        resize=(RESIZE),\n","        n_classes=n_classes,\n","    )\n","\n","    valid_dataset = Dataset(\n","        list_IDs_val,\n","        x_valid_dir,\n","        y_valid_dir,\n","        augmentation=get_validation_augmentation(),\n","        preprocessing=get_preprocessing(preprocessing_fn),\n","        resize=(RESIZE),\n","        to_categorical=TO_CATEGORICAL,\n","        n_classes=n_classes,\n","    )\n","\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=6)\n","    valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=6)\n","\n","    # create epoch runners =========================================================\n","    # it is a simple loop of iterating over dataloader`s samples\n","    train_epoch = smp.utils.train.TrainEpoch(\n","        model,\n","        loss=total_loss,\n","        metrics=metrics,\n","        optimizer=optimizer,\n","        device=DEVICE,\n","        verbose=True,\n","    )\n","\n","    valid_epoch = smp.utils.train.ValidEpoch(\n","        model,\n","        loss=total_loss,\n","        metrics=metrics,\n","        device=DEVICE,\n","        verbose=True,\n","    )\n","\n","    # Train ========================================================================\n","    # train model for N epochs\n","    best_viou = 0.0\n","    best_vloss = 1_000_000.\n","    save_model = False # Initially start with False\n","    cnt_patience = 0\n","\n","    store_train_loss, store_val_loss = [], []\n","    store_train_iou, store_val_iou = [], []\n","    store_train_dice, store_val_dice = [], []\n","\n","    for epoch in range(EPOCHS):\n","\n","        print('\\nEpoch: {}'.format(epoch))\n","        train_logs = train_epoch.run(train_loader)\n","        valid_logs = valid_epoch.run(valid_loader)\n","\n","        # Store losses and metrics\n","        train_loss_key = list(train_logs.keys())[0] # first key is for loss\n","        val_loss_key = list(valid_logs.keys())[0] # first key is for loss\n","\n","        store_train_loss.append(train_logs[train_loss_key])\n","        store_val_loss.append(valid_logs[val_loss_key])\n","        store_train_iou.append(train_logs[\"iou_score\"])\n","        store_val_iou.append(valid_logs[\"iou_score\"])\n","        store_train_dice.append(train_logs[\"fscore\"])\n","        store_val_dice.append(valid_logs[\"fscore\"])\n","\n","        # Track best performance, and save the model's state\n","        if  best_vloss > valid_logs[val_loss_key]:\n","            best_vloss = valid_logs[val_loss_key]\n","            print(f'Validation loss reduced. Saving the model at epoch: {epoch:04d}')\n","            cnt_patience = 0 # reset patience\n","            best_model_epoch = epoch\n","            save_model = True\n","\n","        # Compare iou score\n","        elif best_viou < valid_logs['iou_score']:\n","            best_viou = valid_logs['iou_score']\n","            print(f'Validation IoU increased. Saving the model at epoch: {epoch:04d}.')\n","            cnt_patience = 0 # reset patience\n","            best_model_epoch = epoch\n","            save_model = True\n","\n","        else: cnt_patience += 1\n","\n","        # Learning rate scheduler\n","        scheduler.step(valid_logs[sorted(valid_logs.keys())[0]]) # monitor validation loss\n","\n","        # Save the model\n","        if save_model:\n","            save(os.path.join(checkpoint_loc, 'best_model' + '.pth'),\n","                epoch+1, model.state_dict(), optimizer.state_dict())\n","            save_model = False\n","\n","        # Early stopping\n","        if EARLY_STOP and cnt_patience >= PATIENCE:\n","          print(f\"Early stopping at epoch: {epoch:04d}\")\n","          break\n","\n","        # Periodic checkpoint save\n","        if not SAVE_BEST_MODEL:\n","          if (epoch+1) % PERIOD == 0:\n","            save(os.path.join(checkpoint_loc, f\"cp-{epoch+1:04d}.pth\"),\n","                epoch+1, model.state_dict(), optimizer.state_dict())\n","            print(f'Checkpoint saved for epoch {epoch:04d}')\n","\n","    if not EARLY_STOP and SAVE_LAST_MODEL:\n","        print('Saving last model')\n","        save(os.path.join(checkpoint_loc, 'last_model' + '.pth'),\n","            epoch+1, model.state_dict(), optimizer.state_dict())\n","\n","    print(best_model_epoch)\n","    print('Min validation loss:', np.min(store_val_loss))\n","\n","    end = time.time() # End of training\n","\n","    print(f'Training time: {end - start:.2f} seconds')\n","\n","    # Plot loss curves =============================================================\n","    fig, ax = plt.subplots(1,3, figsize=(12, 3))\n","\n","    ax[0].plot(store_train_loss, 'r')\n","    ax[0].plot(store_val_loss, 'b')\n","    ax[0].set_title('Loss curve')\n","    ax[0].legend(['training', 'validation'])\n","\n","    ax[1].plot(store_train_iou, 'r')\n","    ax[1].plot(store_val_iou, 'b')\n","    ax[1].set_title('IoU curve')\n","    ax[1].legend(['training', 'validation'])\n","\n","    ax[2].plot(store_train_iou, 'r')\n","    ax[2].plot(store_val_iou, 'b')\n","    ax[2].set_title('Dice curve')\n","    ax[2].legend(['training', 'validation'])\n","\n","    fig.tight_layout()\n","\n","    save_fig_dir = \"/content/drive/MyDrive/Wound_tissue_segmentation/plots/\"\n","    if not os.path.exists(save_fig_dir): os.makedirs(save_fig_dir)\n","\n","    fig.savefig(os.path.join(save_fig_dir, model_name + '.png'))\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}